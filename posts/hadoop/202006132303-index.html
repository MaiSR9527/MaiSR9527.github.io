<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>大数据之hadoop：hadoop入门 | maiBlog</title><meta name="description" content="hadoop入门一步步搭建分布式的hadoop集群"><meta name="keywords" content="入门,hadoop"><meta name="author" content="maishuren"><meta name="copyright" content="maishuren"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/bitbug-favicon-32x32.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="dns-prefetch" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://hm.baidu.com"/><link rel="dns-prefetch" href="https://hm.baidu.com"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="dns-prefetch" href="https://fonts.googleapis.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="dns-prefetch" href="//busuanzi.ibruce.info"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="大数据之hadoop：hadoop入门"><meta name="twitter:description" content="hadoop入门一步步搭建分布式的hadoop集群"><meta name="twitter:image" content="https://code.aliyun.com/msr/blog-pic/raw/master/banner/blogbanner8.jpg"><meta property="og:type" content="article"><meta property="og:title" content="大数据之hadoop：hadoop入门"><meta property="og:url" content="http://www.maishuren.top/posts/hadoop/202006132303-"><meta property="og:site_name" content="maiBlog"><meta property="og:description" content="hadoop入门一步步搭建分布式的hadoop集群"><meta property="og:image" content="https://code.aliyun.com/msr/blog-pic/raw/master/banner/blogbanner8.jpg"><meta property="article:published_time" content="2020-06-13T15:03:26.000Z"><meta property="article:modified_time" content="2020-06-26T15:08:24.829Z"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="canonical" href="http://www.maishuren.top/posts/hadoop/202006132303-"><link rel="prev" title="SpringBoot应用：整合actuator和Admin实现SpringBoot监控" href="http://www.maishuren.top/posts/springboot/202006141700-index.html"><link rel="next" title="golang学习八：切片" href="http://www.maishuren.top/posts/gloang/202006131039-index.html"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.js" defer></script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?0d6717a65ff7b5a1f6c9a03d9d87f2f4";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"HLCQW4XQIU","apiKey":"2b769a4e28e86d9b2629a08dec449623","indexName":"myblog","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容:${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: {"bookmark":{"message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  baiduPush: true,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><link rel="stylesheet" href="https://at.alicdn.com/t/font_1900832_ry85jxoks1.css"><meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="maiBlog" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><canvas class="fireworks"></canvas><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://code.aliyun.com/msr/blog-pic/raw/master/blog/newavatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">47</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">26</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">9</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 娱乐</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/playlist/"><i class="fa-fw fa fa-music"></i><span> /歌单</span></a></li></ul></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop是什么？"><span class="toc-number">1.</span> <span class="toc-text">Hadoop是什么？</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop三大发行版本"><span class="toc-number">2.</span> <span class="toc-text">Hadoop三大发行版本</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop的组成"><span class="toc-number">3.</span> <span class="toc-text">Hadoop的组成</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS架构概述"><span class="toc-number">3.1.</span> <span class="toc-text">HDFS架构概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Yarn架构概述"><span class="toc-number">3.2.</span> <span class="toc-text">Yarn架构概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce架构概述"><span class="toc-number">3.3.</span> <span class="toc-text">MapReduce架构概述</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#大数据生态体系"><span class="toc-number">4.</span> <span class="toc-text">大数据生态体系</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#推荐系统框架图"><span class="toc-number">5.</span> <span class="toc-text">推荐系统框架图</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop运行环境搭建"><span class="toc-number">6.</span> <span class="toc-text">Hadoop运行环境搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#安装JDK和安装Hadoop"><span class="toc-number">6.1.</span> <span class="toc-text">安装JDK和安装Hadoop</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop目录结构"><span class="toc-number">6.2.</span> <span class="toc-text">Hadoop目录结构</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop运行模式"><span class="toc-number">7.</span> <span class="toc-text">Hadoop运行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#本地运行模式"><span class="toc-number">7.1.</span> <span class="toc-text">本地运行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#官方Grep案例"><span class="toc-number">7.1.1.</span> <span class="toc-text">官方Grep案例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#官方WordCount程序"><span class="toc-number">7.1.2.</span> <span class="toc-text">官方WordCount程序</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#伪分布式运行模式"><span class="toc-number">7.2.</span> <span class="toc-text">伪分布式运行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#启动HDFS并运行MapReduce程序"><span class="toc-number">7.2.1.</span> <span class="toc-text">启动HDFS并运行MapReduce程序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#启动YARN并运行MapReduce程序"><span class="toc-number">7.2.2.</span> <span class="toc-text">启动YARN并运行MapReduce程序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#配置历史服务器"><span class="toc-number">7.2.3.</span> <span class="toc-text">配置历史服务器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#配置日志的聚集"><span class="toc-number">7.2.4.</span> <span class="toc-text">配置日志的聚集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#配置文件说明"><span class="toc-number">7.2.5.</span> <span class="toc-text">配置文件说明</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#完全分布式运行模式"><span class="toc-number">7.3.</span> <span class="toc-text">完全分布式运行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#编写集群分发脚本"><span class="toc-number">7.3.1.</span> <span class="toc-text">编写集群分发脚本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#集群配置"><span class="toc-number">7.3.2.</span> <span class="toc-text">集群配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#配置ssh免密码登录"><span class="toc-number">7.3.3.</span> <span class="toc-text">配置ssh免密码登录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#群起集群配置"><span class="toc-number">7.3.4.</span> <span class="toc-text">群起集群配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#启动测试"><span class="toc-number">7.3.5.</span> <span class="toc-text">启动测试</span></a></li></ol></li></ol></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(https://code.aliyun.com/msr/blog-pic/raw/master/banner/blogbanner8.jpg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">maiBlog</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 娱乐</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/playlist/"><i class="fa-fw fa fa-music"></i><span> /歌单</span></a></li></ul></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">大数据之hadoop：hadoop入门</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-06-13 23:03:26"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-06-13</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-06-26 23:08:24"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-06-26</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="post-meta__icon fa fa-file-word-o" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">10.1k</span><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-clock-o" aria-hidden="true"></i><span>阅读时长: 52 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-comment-o" aria-hidden="true"></i><span>评论数:</span><a href="/posts/hadoop/202006132303-index.html#post-comment" itemprop="discussionUrl"><span class="valine-comment-count comment-count" data-xid="/posts/hadoop/202006132303-index.html" itemprop="commentCount"></span></a></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="Hadoop是什么？"><a href="#Hadoop是什么？" class="headerlink" title="Hadoop是什么？"></a>Hadoop是什么？</h1><p>1）hadoop是由Apache基金会所开发的分布式系统基础架构</p>
<p>2）主要解决海量数据的存储和海量数据的分析计算问题</p>
<p>3）广义来说，hadoop通常是之一个更广泛的概念—hadoop生态圈</p>
<p><img src="https://code.aliyun.com/msr/blog-pic/raw/master/hadoop/hadoop1.jpg" alt=""></p>
<h1 id="Hadoop三大发行版本"><a href="#Hadoop三大发行版本" class="headerlink" title="Hadoop三大发行版本"></a>Hadoop三大发行版本</h1><p>Hadoop三大发行版本：Apache、Cloudera、Hortonworks。</p>
<p>Apache版本最原始（最基础）的版本，对于入门学习最好。</p>
<p>Cloudera在大型互联网企业中用的较多。</p>
<p>Hortonworks文档较好。</p>
<ol>
<li>Apache Hadoop</li>
</ol>
<p>官网地址：<a href="http://hadoop.apache.org/releases.html" target="_blank" rel="noopener">http://hadoop.apache.org/releases.html</a></p>
<p>下载地址：<a href="https://archive.apache.org/dist/hadoop/common/" target="_blank" rel="noopener">https://archive.apache.org/dist/hadoop/common/</a></p>
<ol start="2">
<li>Cloudera Hadoop </li>
</ol>
<p>官网地址：<a href="https://www.cloudera.com/downloads/cdh/5-10-0.html" target="_blank" rel="noopener">https://www.cloudera.com/downloads/cdh/5-10-0.html</a></p>
<p>下载地址：<a href="http://archive-primary.cloudera.com/cdh5/cdh/5/" target="_blank" rel="noopener">http://archive-primary.cloudera.com/cdh5/cdh/5/</a></p>
<p>（1）2008年成立的Cloudera是最早将Hadoop商用的公司，为合作伙伴提供Hadoop的商用解决方案，主要是包括支持、咨询服务、培训。</p>
<p>（2）2009年Hadoop的创始人Doug Cutting也加盟Cloudera公司。Cloudera产品主要为CDH，Cloudera Manager，Cloudera Support</p>
<p>（3）CDH是Cloudera的Hadoop发行版，完全开源，比Apache Hadoop在兼容性，安全性，稳定性上有所增强。</p>
<p>（4）Cloudera Manager是集群的软件分发及管理监控平台，可以在几个小时内部署好一个Hadoop集群，并对集群的节点及服务进行实时监控。Cloudera Support即是对Hadoop的技术支持。</p>
<p>（5）Cloudera的标价为每年每个节点4000美元。Cloudera开发并贡献了可实时处理大数据的Impala项目。</p>
<ol start="3">
<li>Hortonworks Hadoop</li>
</ol>
<p>官网地址：<a href="https://hortonworks.com/products/data-center/hdp/" target="_blank" rel="noopener">https://hortonworks.com/products/data-center/hdp/</a></p>
<p>下载地址：<a href="https://hortonworks.com/downloads/#data-platform" target="_blank" rel="noopener">https://hortonworks.com/downloads/#data-platform</a></p>
<p>（1）2011年成立的Hortonworks是雅虎与硅谷风投公司Benchmark Capital合资组建。</p>
<p>（2）公司成立之初就吸纳了大约25名至30名专门研究Hadoop的雅虎工程师，上述工程师均在2005年开始协助雅虎开发Hadoop，贡献了Hadoop80%的代码。</p>
<p>（3）雅虎工程副总裁、雅虎Hadoop开发团队负责人Eric Baldeschwieler出任Hortonworks的首席执行官。</p>
<p>（4）Hortonworks的主打产品是Hortonworks Data Platform（HDP），也同样是100%开源的产品，HDP除常见的项目外还包括了Ambari，一款开源的安装和管理系统。</p>
<p>（5）HCatalog，一个元数据管理系统，HCatalog现已集成到Facebook开源的Hive中。Hortonworks的Stinger开创性的极大的优化了Hive项目。Hortonworks为入门提供了一个非常好的，易于使用的沙盒。</p>
<p>（6）Hortonworks开发了很多增强特性并提交至核心主干，这使得Apache Hadoop能够在包括Window Server和Windows Azure在内的Microsoft Windows平台上本地运行。定价以集群为基础，每10个节点每年为12500美元。</p>
<h1 id="Hadoop的组成"><a href="#Hadoop的组成" class="headerlink" title="Hadoop的组成"></a>Hadoop的组成</h1><p><img src="https://code.aliyun.com/msr/blog-pic/raw/master/hadoop/hadoop2.png" alt=""></p>
<h2 id="HDFS架构概述"><a href="#HDFS架构概述" class="headerlink" title="HDFS架构概述"></a>HDFS架构概述</h2><p>HDFS由NameNode、DataNode、SencodaryNode组成。</p>
<ul>
<li>NameNode：存储文件的元数据，如文件名，文件目录结构，文件属性(生成时间、副本数、文件权限)，以及每个文件的块列表和块所在的DataNode等。</li>
<li>DataNode：在本地文件系统存储文件块数据，以及块数据的校验和。</li>
<li>SecondaryNode：用于监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。</li>
</ul>
<h2 id="Yarn架构概述"><a href="#Yarn架构概述" class="headerlink" title="Yarn架构概述"></a>Yarn架构概述</h2><p><img src="https://code.aliyun.com/msr/blog-pic/raw/master/hadoop/hadoop3.png" alt=""></p>
<h2 id="MapReduce架构概述"><a href="#MapReduce架构概述" class="headerlink" title="MapReduce架构概述"></a>MapReduce架构概述</h2><p>MapReduce将计算过程分为两个阶段：Map和Reduce</p>
<p>1）Map阶段并行处理输入数据</p>
<p>2）Reduce阶段对Map结果进行汇总</p>
<p><img src="https://code.aliyun.com/msr/blog-pic/raw/master/hadoop/hadoop4.png" alt=""></p>
<h1 id="大数据生态体系"><a href="#大数据生态体系" class="headerlink" title="大数据生态体系"></a>大数据生态体系</h1><p><img src="https://code.aliyun.com/msr/blog-pic/raw/master/hadoop/hadoop11.jpg" alt=""></p>
<p>1）Sqoop：Sqoop是一款开源的工具，主要用于在Hadoop、Hive与传统的数据库(MySql)间进行数据的传递，可以将一个关系型数据库（例如 ：MySQL，Oracle 等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。</p>
<p>2）Flume：Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。</p>
<p>3）Kafka：Kafka是一种高吞吐量的分布式发布订阅消息系统，有如下特性：</p>
<p>（1）通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。</p>
<p>（2）高吞吐量：即使是非常普通的硬件Kafka也可以支持每秒数百万的消息。</p>
<p>（3）支持通过Kafka服务器和消费机集群来分区消息。</p>
<p>（4）支持Hadoop并行数据加载。</p>
<p>4）Storm：Storm用于“连续计算”，对数据流做连续查询，在计算时就将结果以流的形式输出给用户。</p>
<p>5）Spark：Spark是当前最流行的开源大数据内存计算框架。可以基于Hadoop上存储的大数据进行计算。</p>
<p>6）Oozie：Oozie是一个管理Hdoop作业（job）的工作流程调度管理系统。</p>
<p>7）Hbase：HBase是一个分布式的、面向列的开源数据库。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。</p>
<p>8）Hive：Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的SQL查询功能，可以将SQL语句转换为MapReduce任务进行运行。 其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。</p>
<p>10）R语言：R是用于统计分析、绘图的语言和操作环境。R是属于GNU系统的一个自由、免费、源代码开放的软件，它是一个用于统计计算和统计制图的优秀工具。</p>
<p>11）Mahout：Apache Mahout是个可扩展的机器学习和数据挖掘库。</p>
<p>12）ZooKeeper：Zookeeper是Google的Chubby一个开源的实现。它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、 分布式同步、组服务等。ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。</p>
<h1 id="推荐系统框架图"><a href="#推荐系统框架图" class="headerlink" title="推荐系统框架图"></a>推荐系统框架图</h1><p><img src="https://code.aliyun.com/msr/blog-pic/raw/master/hadoop/hadoop12.jpg" alt=""></p>
<h1 id="Hadoop运行环境搭建"><a href="#Hadoop运行环境搭建" class="headerlink" title="Hadoop运行环境搭建"></a>Hadoop运行环境搭建</h1><h2 id="安装JDK和安装Hadoop"><a href="#安装JDK和安装Hadoop" class="headerlink" title="安装JDK和安装Hadoop"></a>安装JDK和安装Hadoop</h2><p>在根目录的opt目录下新建software目录，再在software目录下新建bigdata目录，hadoop和jdk的压缩包都放在bigdata目录下。</p>
<p>1.解压jdk压缩包</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf jdk-8u211-linux-x64.tar.gz</span><br></pre></td></tr></table></figure>

<p>2.解压Hadoop压缩包</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf hadoop-2.7.2.tar.gz</span><br></pre></td></tr></table></figure>

<p>3.配置环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/software/bigdata/jdk1.8</span><br><span class="line">export JRE_HOME=/opt/software/bigdata/jdk1.8/jre</span><br><span class="line">export HADOOP_HOME=/opt/software/bigdata/hadoop</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH</span><br><span class="line">export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>

<p>4.验证环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]# java -version</span><br><span class="line">java version "1.8.0_211"</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_211-b12)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode)</span><br><span class="line"></span><br><span class="line">[root@centos7 hadoop]# hadoop version</span><br><span class="line">Hadoop 2.7.2</span><br><span class="line">Subversion Unknown -r Unknown</span><br><span class="line">Compiled by root on 2017-05-22T10:49Z</span><br><span class="line">Compiled with protoc 2.5.0</span><br><span class="line">From source with checksum d0fda26633fa762bff87ec759ebe689c</span><br><span class="line">This command was run using /opt/software/bigdata/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar</span><br></pre></td></tr></table></figure>

<p>配置成功！</p>
<h2 id="Hadoop目录结构"><a href="#Hadoop目录结构" class="headerlink" title="Hadoop目录结构"></a>Hadoop目录结构</h2><p>1、查看Hadoop目录结构</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101 hadoop-2.7.2]$ ll</span><br><span class="line">总用量 52</span><br><span class="line">drwxr-xr-x. 2 atguigu atguigu 4096 5月 22 2017 **bin**</span><br><span class="line">drwxr-xr-x. 3 atguigu atguigu 4096 5月 22 2017 **etc**</span><br><span class="line">drwxr-xr-x. 2 atguigu atguigu 4096 5月 22 2017 include</span><br><span class="line">drwxr-xr-x. 3 atguigu atguigu 4096 5月 22 2017 **lib**</span><br><span class="line">drwxr-xr-x. 2 atguigu atguigu 4096 5月 22 2017 libexec</span><br><span class="line">-rw-r--r--. 1 atguigu atguigu 15429 5月 22 2017 LICENSE.txt</span><br><span class="line">-rw-r--r--. 1 atguigu atguigu  101 5月 22 2017 NOTICE.txt</span><br><span class="line">-rw-r--r--. 1 atguigu atguigu 1366 5月 22 2017 README.txt</span><br><span class="line">drwxr-xr-x. 2 atguigu atguigu 4096 5月 22 2017 **sbin**</span><br><span class="line">drwxr-xr-x. 4 atguigu atguigu 4096 5月 22 2017 **share**</span><br></pre></td></tr></table></figure>

<p>2、重要目录</p>
<p>（1）bin目录：存放对Hadoop相关服务（HDFS,YARN）进行操作的脚本</p>
<p>（2）etc目录：Hadoop的配置文件目录，存放Hadoop的配置文件</p>
<p>（3）lib目录：存放Hadoop的本地库（对数据进行压缩解压缩功能）</p>
<p>（4）sbin目录：存放启动或停止Hadoop相关服务的脚本</p>
<p>（5）share目录：存放Hadoop的依赖jar包、文档、和官方案例</p>
<h1 id="Hadoop运行模式"><a href="#Hadoop运行模式" class="headerlink" title="Hadoop运行模式"></a>Hadoop运行模式</h1><p>Hadoop运行模式包括：本地模式、伪分布式模式以及完全分布式模式。</p>
<p>Hadoop官方网站：<a href="http://hadoop.apache.org/" target="_blank" rel="noopener">http://hadoop.apache.org/</a></p>
<h2 id="本地运行模式"><a href="#本地运行模式" class="headerlink" title="本地运行模式"></a>本地运行模式</h2><h3 id="官方Grep案例"><a href="#官方Grep案例" class="headerlink" title="官方Grep案例"></a>官方Grep案例</h3><ol>
<li>创建在hadoop-2.7.2文件下面创建一个input文件夹</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ mkdir input</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>将Hadoop的xml配置文件复制到input</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ cp etc/hadoop/*.xml input</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>执行share目录下的MapReduce程序</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output 'dfs[a-z.]+'</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>查看输出结果</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ cat output/*</span><br></pre></td></tr></table></figure>

<h3 id="官方WordCount程序"><a href="#官方WordCount程序" class="headerlink" title="官方WordCount程序"></a>官方WordCount程序</h3><ol>
<li>创建在hadoop文件下面创建一个wcinput文件夹</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ mkdir wcinput</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>在wcinput文件下创建一个wc.input文件</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ cd wcinput</span><br><span class="line"></span><br><span class="line">[root@centos7 hadoop]$ touch wc.input</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>编辑wc.input文件</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ vim wc.input</span><br><span class="line"></span><br><span class="line">hadoop yarn</span><br><span class="line">hadoop mapreduce</span><br><span class="line">root</span><br><span class="line">root</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>回到Hadoop目录，执行程序</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount wcinput wcoutput</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>查看结果</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ cat wcoutput/part-r-00000</span><br><span class="line"></span><br><span class="line">root 2</span><br><span class="line">hadoop 2</span><br><span class="line">mapreduce    1</span><br><span class="line">yarn  1</span><br></pre></td></tr></table></figure>

<h2 id="伪分布式运行模式"><a href="#伪分布式运行模式" class="headerlink" title="伪分布式运行模式"></a>伪分布式运行模式</h2><h3 id="启动HDFS并运行MapReduce程序"><a href="#启动HDFS并运行MapReduce程序" class="headerlink" title="启动HDFS并运行MapReduce程序"></a>启动HDFS并运行MapReduce程序</h3><ol>
<li>分析</li>
</ol>
<p>​    （1）配置集群</p>
<p>​    （2）启动、测试集群增、删、查</p>
<p>​    （3）执行WordCount案例</p>
<ol start="2">
<li>执行步骤</li>
</ol>
<p>（1）配置集群</p>
<p>​       （a）配置：hadoop-env.sh</p>
<p>​         Linux系统中获取JDK的安装路径：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 ~]# echo $JAVA_HOME</span><br><span class="line"></span><br><span class="line">/opt/module/jdk1.8.0_211</span><br></pre></td></tr></table></figure>

<p>​        修改hadoop-env.sh中的JAVA_HOME 路径：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_211</span><br></pre></td></tr></table></figure>

<p>（b）配置：core-site.xml</p>
  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定HDFS中NameNode的地址  --&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span>      </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop1:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>     </span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录  --&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（c）配置：hdfs-site.xml</p>
  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--  指定HDFS副本的数量 --&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）启动集群</p>
<p>​    （a）格式化<strong>NameNode</strong>（第一次启动时格式化，以后就不要总格式化）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>

<p>​    （b）启动NameNode</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ sbin/hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure>

<p>​    （c）启动DataNode</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ sbin&#x2F;hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure>

<p>（3）查看集群</p>
<p>​    （a）查看是否启动成功</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ jps</span><br><span class="line"></span><br><span class="line">13586 NameNode</span><br><span class="line">13668 DataNode</span><br><span class="line">13786 Jps</span><br></pre></td></tr></table></figure>

<p>​    （b）web端查看HDFS文件系统</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;ip:50070&#x2F;dfshealth.html#tab-overview</span><br></pre></td></tr></table></figure>

<p>​    （c）查看产生的Log日志</p>
<p>​        说明：在企业中遇到Bug时，经常根据日志提示信息去分析问题、解决Bug。</p>
<p>当前目录：hadoop/logs</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 logs]$ ls</span><br><span class="line"></span><br><span class="line">hadoop-root-datanode-hadoop.root.com.log</span><br><span class="line">hadoop-root-datanode-hadoop.root.com.out</span><br><span class="line">hadoop-root-namenode-hadoop.root.com.log</span><br><span class="line">hadoop-root-namenode-hadoop.root.com.out</span><br><span class="line">SecurityAuth-root.audit</span><br><span class="line"></span><br><span class="line">[root@centos7 logs]$ cat hadoop-root-datanode-hadoop101.log</span><br><span class="line"></span><br><span class="line">[root@centos7 hadoop]$ cd data/tmp/dfs/name/current/</span><br><span class="line"></span><br><span class="line">[root@centos7 current]$ cat VERSION</span><br><span class="line"></span><br><span class="line">**clusterID=CID-f0330a58-36fa-4a2a-a65f-2688269b5837**</span><br><span class="line"></span><br><span class="line">[root@centos7 hadoop]$ cd data/tmp/dfs/data/current/</span><br><span class="line"></span><br><span class="line">**clusterID=CID-f0330a58-36fa-4a2a-a65f-2688269b5837**</span><br></pre></td></tr></table></figure>

<p>注意：格式化NameNode，会产生新的集群id,导致NameNode和DataNode的集群id不一致，集群找不到已往数据。所以，格式NameNode时，一定要先删除data数据和log日志，然后再格式化NameNode。</p>
<p>（4）操作集群</p>
<p>​       （a）在HDFS文件系统上<strong>创建</strong>一个input文件夹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ bin/hdfs dfs -mkdir -p /user/atguigu/input</span><br></pre></td></tr></table></figure>

<p>​       （b）将测试文件内容<strong>上传</strong>到文件系统上</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$bin/hdfs dfs -put wcinput/wc.input</span><br><span class="line"></span><br><span class="line">/user/root/input/</span><br></pre></td></tr></table></figure>

<p>​       （c）<strong>查看</strong>上传的文件是否正确</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ bin/hdfs dfs -ls /user/atguigu/input/</span><br><span class="line"></span><br><span class="line">[root@centos7 hadoop]$ bin/hdfs dfs -cat /user/atguigu/ input/wc.input</span><br></pre></td></tr></table></figure>

<p>​       （d）运行MapReduce程序</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/root/input/ /user/root/output</span><br></pre></td></tr></table></figure>

<p>​        （e）查看输出结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ bin/hdfs dfs -cat /user/root/output/*</span><br></pre></td></tr></table></figure>

<p>浏览器查看，如图所示 查看output文件</p>
<p><img src="https://code.aliyun.com/msr/blog-pic/raw/master/hadoop/hadoop5.png" alt=""></p>
<p>​       （f）将测试文件内容<strong>下载</strong>到本地</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ hdfs dfs -get /user/atguigu/output/part-r-00000 ./wcoutput/</span><br></pre></td></tr></table></figure>

<p>​      （g）<strong>删除</strong>输出结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ hdfs dfs -rm -r /user/atguigu/output</span><br></pre></td></tr></table></figure>

<h3 id="启动YARN并运行MapReduce程序"><a href="#启动YARN并运行MapReduce程序" class="headerlink" title="启动YARN并运行MapReduce程序"></a>启动YARN并运行MapReduce程序</h3><ol>
<li>分析</li>
</ol>
<p>​    （1）配置集群在YARN上运行MR</p>
<p>​    （2）启动、测试集群增、删、查</p>
<p>​    （3）在YARN上执行WordCount案例</p>
<ol start="2">
<li>执行步骤    </li>
</ol>
<p>​    （1）配置集群</p>
<p>​       （a）配置yarn-env.sh.配置一下JAVA_HOME</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_211</span><br></pre></td></tr></table></figure>

<p>​        （b）配置yarn-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Reducer获取数据的方式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop101<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>​       （c）配置：mapred-env.sh.配置一下JAVA_HOME</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure>

<p>​       （d）配置： (对mapred-site.xml.template重新命名为) mapred-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ mv mapred-site.xml.template mapred-site.xml</span><br><span class="line">[root@centos7 hadoop]$ vim mapred-site.xml</span><br></pre></td></tr></table></figure>



<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定MR运行在YARN上 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）启动集群</p>
<p>​    （a）启动前必须保证NameNode和DataNode已经启动</p>
<p>​    （b）启动ResourceManager</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ sbin/yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure>

<p>​    （c）启动NodeManager</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ sbin/yarn-daemon.sh start nodemanager</span><br></pre></td></tr></table></figure>

<p>  （3）集群操作</p>
<p>​    （a）YARN的浏览器页面查看，如图所示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;ip:8088&#x2F;cluster</span><br></pre></td></tr></table></figure>

<p> YARN的浏览器页面<img src="https://code.aliyun.com/msr/blog-pic/raw/master/hadoop/hadoop6.png" alt=""></p>
<p>​       （b）删除文件系统上的output文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ bin/hdfs dfs -rm -R /user/atguigu/output</span><br></pre></td></tr></table></figure>

<p>​       （c）执行MapReduce程序</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/atguigu/input /user/atguigu/output</span><br></pre></td></tr></table></figure>

<p>​       （d）查看运行结果，如图所示</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ bin/hdfs dfs -cat /user/atguigu/output/*</span><br></pre></td></tr></table></figure>

<p><img src="https://code.aliyun.com/msr/blog-pic/raw/master/hadoop/hadoop7.png" alt=""></p>
<h3 id="配置历史服务器"><a href="#配置历史服务器" class="headerlink" title="配置历史服务器"></a>配置历史服务器</h3><p>为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下：</p>
<ol>
<li>配置mapred-site.xml</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ vim mapred-site.xml</span><br></pre></td></tr></table></figure>

<p>在该文件里面增加如下配置。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop101:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 历史服务器web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop101:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>启动历史服务器</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ sbin&#x2F;mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>查看历史服务器是否启动</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$jps</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>查看JobHistory：<a href="http://ip:19888/jobgistory" target="_blank" rel="noopener">http://ip:19888/jobgistory</a></li>
</ol>
<h3 id="配置日志的聚集"><a href="#配置日志的聚集" class="headerlink" title="配置日志的聚集"></a>配置日志的聚集</h3><p>日志聚集概念：应用运行完成以后，将程序运行日志信息上传到HDFS系统上。</p>
<p>日志聚集功能好处：可以方便的查看到程序运行详情，方便开发调试。</p>
<p>注意：开启日志聚集功能，需要重新启动NodeManager 、ResourceManager和HistoryManager。</p>
<p>开启日志聚集功能具体步骤如下：</p>
<ol>
<li>配置yarn-site.xml</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ vi yarn-site.xml</span><br></pre></td></tr></table></figure>

<p>在该文件里面增加如下配置。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 日志聚集功能使能 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 日志保留时间设置7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>关闭NodeManager 、ResourceManager和HistoryServer</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ sbin/yarn-daemon.sh stop resourcemanager</span><br><span class="line"></span><br><span class="line">[root@centos7 hadoop]$ sbin/yarn-daemon.sh stop nodemanager</span><br><span class="line"></span><br><span class="line">[root@centos7 hadoop]$ sbin/mr-jobhistory-daemon.sh stop historyserver</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>启动NodeManager 、ResourceManager和HistoryServer</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$]$ sbin/yarn-daemon.sh start resourcemanager</span><br><span class="line"></span><br><span class="line">[root@centos7 hadoop]$ sbin/yarn-daemon.sh start nodemanager</span><br><span class="line"></span><br><span class="line">[root@centos7 hadoop]$ sbin/mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>删除HDFS上已经存在的输出文件</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ bin/hdfs dfs -rm -R /user/atguigu/output</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>执行WordCount程序</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 hadoop]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/atguigu/input /user/atguigu/output</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>查看日志，如图所示</li>
</ol>
<p><a href="http://hadoop101:19888/jobhistory" target="_blank" rel="noopener">http://hadoop101:19888/jobhistory</a></p>
<p> Job History</p>
<p><img src="https://code.aliyun.com/msr/blog-pic/raw/master/hadoop/hadoop8.png" alt=""></p>
<p>job运行情况<img src="https://code.aliyun.com/msr/blog-pic/raw/master/hadoop/hadoop9.png" alt=""></p>
<p>查看日志<img src="https://code.aliyun.com/msr/blog-pic/raw/master/hadoop/hadoop10.png" alt=""></p>
<h3 id="配置文件说明"><a href="#配置文件说明" class="headerlink" title="配置文件说明"></a>配置文件说明</h3><p>Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。</p>
<p>（1）默认配置文件：</p>
<table>
<thead>
<tr>
<th>要获取的默认文件</th>
<th>文件存放在Hadoop的jar包中的位置</th>
</tr>
</thead>
<tbody><tr>
<td>core-default.xml</td>
<td>hadoop-common-2.7.2.jar/  core-default.xml</td>
</tr>
<tr>
<td>hdfs-default.xml</td>
<td>hadoop-hdfs-2.7.2.jar/  hdfs-default.xml</td>
</tr>
<tr>
<td>yarn-default.xml</td>
<td>hadoop-yarn-common-2.7.2.jar/  yarn-default.xml</td>
</tr>
<tr>
<td>mapred-default.xml</td>
<td>hadoop-mapreduce-client-core-2.7.2.jar/  mapred-default.xml</td>
</tr>
</tbody></table>
<p>（2）自定义配置文件：</p>
<p>​    core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置。</p>
<h2 id="完全分布式运行模式"><a href="#完全分布式运行模式" class="headerlink" title="完全分布式运行模式"></a>完全分布式运行模式</h2><h3 id="编写集群分发脚本"><a href="#编写集群分发脚本" class="headerlink" title="编写集群分发脚本"></a>编写集群分发脚本</h3><p>rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。</p>
<p>rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。</p>
<p>rsync语法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rsync  -av      $pdir&#x2F;$fname          $user@host:$pdir&#x2F;$fname</span><br><span class="line">命令   选项参数   要拷贝的文件路径&#x2F;名称    目的用户@主机:目的路径&#x2F;名称</span><br></pre></td></tr></table></figure>

<p>通过vim编写xsync:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">#1 获取输入参数个数，如果没有参数，直接退出</span><br><span class="line">pcount&#x3D;$#</span><br><span class="line">if ((pcount&#x3D;&#x3D;0)); then</span><br><span class="line">echo no args;</span><br><span class="line">exit;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">#2 获取文件名称</span><br><span class="line">p1&#x3D;$1</span><br><span class="line">fname&#x3D;&#96;basename $p1&#96;</span><br><span class="line">echo fname&#x3D;$fname</span><br><span class="line"></span><br><span class="line">#3 获取上级目录到绝对路径</span><br><span class="line">pdir&#x3D;&#96;cd -P $(dirname $p1); pwd&#96;</span><br><span class="line">echo pdir&#x3D;$pdir</span><br><span class="line"></span><br><span class="line">#4 获取当前用户名称</span><br><span class="line">user&#x3D;&#96;whoami&#96;</span><br><span class="line"></span><br><span class="line">#5 循环</span><br><span class="line">for((host&#x3D;1; host&lt;4; host++)); do</span><br><span class="line">        echo ------------------- hadoop$host --------------</span><br><span class="line">        rsync -av $pdir&#x2F;$fname $user@hadoop$host:$pdir</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<p>修改权限：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 bigdata]$ chmod 777 xsync</span><br></pre></td></tr></table></figure>

<p>测试:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 bigdata]$ mv xsync &#x2F;usr&#x2F;local&#x2F;bin&#x2F;</span><br></pre></td></tr></table></figure>

<p>如果报错：rsync: command not found，需要安装rsync</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install rsync -y</span><br></pre></td></tr></table></figure>

<h3 id="集群配置"><a href="#集群配置" class="headerlink" title="集群配置"></a>集群配置</h3><ol>
<li>集群规划</li>
</ol>
<table>
<thead>
<tr>
<th></th>
<th>hadoop1</th>
<th>hadoop2</th>
<th>hadoop3</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>NameNode  DataNode</td>
<td>DataNode</td>
<td>SecondaryNameNode  DataNode</td>
</tr>
<tr>
<td>YARN</td>
<td>NodeManager</td>
<td>ResourceManager  NodeManager</td>
<td>NodeManager</td>
</tr>
</tbody></table>
<ol start="2">
<li><p>修改配置文件</p>
<p>1) 核心配置文件：core-site.xml</p>
</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop1:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/software/bigdata/hadoop/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>​        2) HDFS配置文件</p>
<p>​        hadoop.env</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 配置jdk所在的目录</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;jdk1.8</span><br></pre></td></tr></table></figure>

<p>​        hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--指定hdfs的副本数量--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop辅助名称节点主机配置：SecondaryNameNode  --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop3:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>​        3) yarn配置文件</p>
<p>​        yarn-env.sh</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 配置jdk所在的目录</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;jdk1.8</span><br></pre></td></tr></table></figure>

<p>​        yarn-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Reducer获取数据的方式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>​        4) MapperReducer配置文件</p>
<p>​        mapred-env.sh</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 配置jdk所在的目录</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;jdk1.8</span><br></pre></td></tr></table></figure>

<p>​        mapred-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#根据模板修改</span><br><span class="line">cp mapred-site.xml.template mapred-site.xml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定MR运行在Yarn上 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>修改完成后，通过集群分发脚本分发到各个服务器上</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop1 bigdata]$ xsync &#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>在配置了NameNode的服务器上格式化集群</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop1 bigdata]$ hdfs namenode -format</span><br><span class="line">#出现一下一大堆的配置信息</span><br><span class="line"></span><br><span class="line">[root@msr-server hadoop]# hdfs namenode -format</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:04 INFO namenode.NameNode: STARTUP_MSG: </span><br><span class="line">&#x2F;************************************************************</span><br><span class="line">STARTUP_MSG: Starting NameNode</span><br><span class="line">STARTUP_MSG:   host &#x3D; msr-server&#x2F;192.168.74.129</span><br><span class="line">STARTUP_MSG:   args &#x3D; [-format]</span><br><span class="line">STARTUP_MSG:   version &#x3D; 2.7.2</span><br><span class="line">STARTUP_MSG:   classpath &#x3D; &#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;etc&#x2F;hadoop:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;commons-io-2.4.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;commons-lang-2.6.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;commons-beanutils-1.7.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;mockito-all-1.8.5.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;commons-digester-1.8.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;jackson-xc-1.9.13.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;servlet-api-2.5.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;slf4j-api-1.7.10.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;hamcrest-core-1.3.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;log4j-1.2.17.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;jackson-core-asl-1.9.13.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;htrace-core-3.1.0-incubating.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;gson-2.2.4.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;commons-logging-1.1.3.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;apacheds-kerberos-codec-2.0.0-M15.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;commons-cli-1.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;commons-collections-3.2.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;asm-3.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;jackson-jaxrs-1.9.13.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;xz-1.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;jersey-server-1.9.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;jersey-core-1.9.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;protobuf-java-2.5.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;paranamer-2.3.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;slf4j-log4j12-1.7.10.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;jackson-mapper-asl-1.9.13.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;commons-codec-1.4.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;httpclient-4.2.5.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;jettison-1.1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;jetty-util-6.1.26.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;activation-1.1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;zookeeper-3.4.6.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;jets3t-0.9.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;commons-configuration-1.6.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;junit-4.11.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;jsp-api-2.1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;guava-11.0.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;avro-1.7.4.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;jsr305-3.0.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;jsch-0.1.42.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;commons-beanutils-core-1.8.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;apacheds-i18n-2.0.0-M15.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;commons-httpclient-3.1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;jetty-6.1.26.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;java-xmlbuilder-0.4.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;curator-framework-2.7.1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;jersey-json-1.9.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;netty-3.6.2.Final.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;curator-client-2.7.1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;stax-api-1.0-2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;snappy-java-1.0.4.1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;api-util-1.0.0-M20.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;commons-compress-1.4.1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;xmlenc-0.52.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;commons-math3-3.1.1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;httpcore-4.2.5.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;api-asn1-api-1.0.0-M20.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;hadoop-annotations-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;jaxb-api-2.2.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;jaxb-impl-2.2.3-1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;commons-net-3.1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;curator-recipes-2.7.1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;hadoop-auth-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;hadoop-nfs-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;hadoop-common-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;hadoop-common-2.7.2-tests.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;commons-io-2.4.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;commons-lang-2.6.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;xercesImpl-2.9.1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;servlet-api-2.5.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;xml-apis-1.3.04.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;log4j-1.2.17.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;jackson-core-asl-1.9.13.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;htrace-core-3.1.0-incubating.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;commons-logging-1.1.3.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;commons-cli-1.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;asm-3.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;leveldbjni-all-1.8.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;jersey-server-1.9.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;jersey-core-1.9.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;protobuf-java-2.5.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;jackson-mapper-asl-1.9.13.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;commons-codec-1.4.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;jetty-util-6.1.26.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;guava-11.0.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;jsr305-3.0.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;jetty-6.1.26.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;netty-3.6.2.Final.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;commons-daemon-1.0.13.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;xmlenc-0.52.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;lib&#x2F;netty-all-4.0.23.Final.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;hadoop-hdfs-nfs-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;hadoop-hdfs-2.7.2-tests.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;hdfs&#x2F;hadoop-hdfs-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;jersey-guice-1.9.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;commons-io-2.4.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;commons-lang-2.6.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;jackson-xc-1.9.13.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;servlet-api-2.5.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;log4j-1.2.17.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;jackson-core-asl-1.9.13.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;commons-logging-1.1.3.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;commons-cli-1.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;guice-3.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;commons-collections-3.2.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;asm-3.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;leveldbjni-all-1.8.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;jackson-jaxrs-1.9.13.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;jersey-client-1.9.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;xz-1.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;jersey-server-1.9.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;jersey-core-1.9.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;protobuf-java-2.5.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;jackson-mapper-asl-1.9.13.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;commons-codec-1.4.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;jettison-1.1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;jetty-util-6.1.26.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;activation-1.1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;zookeeper-3.4.6.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;aopalliance-1.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;guava-11.0.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;jsr305-3.0.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;javax.inject-1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;jetty-6.1.26.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;jersey-json-1.9.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;netty-3.6.2.Final.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;stax-api-1.0-2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;guice-servlet-3.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;zookeeper-3.4.6-tests.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;commons-compress-1.4.1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;jaxb-api-2.2.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib&#x2F;jaxb-impl-2.2.3-1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;hadoop-yarn-server-resourcemanager-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;hadoop-yarn-server-sharedcachemanager-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;hadoop-yarn-server-tests-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;hadoop-yarn-applications-distributedshell-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;hadoop-yarn-server-common-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;hadoop-yarn-server-nodemanager-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;hadoop-yarn-api-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;hadoop-yarn-common-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;hadoop-yarn-registry-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;hadoop-yarn-server-web-proxy-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;hadoop-yarn-client-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;jersey-guice-1.9.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;commons-io-2.4.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;hamcrest-core-1.3.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;log4j-1.2.17.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;jackson-core-asl-1.9.13.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;guice-3.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;asm-3.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;leveldbjni-all-1.8.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;xz-1.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;jersey-server-1.9.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;jersey-core-1.9.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;protobuf-java-2.5.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;paranamer-2.3.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;jackson-mapper-asl-1.9.13.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;aopalliance-1.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;junit-4.11.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;avro-1.7.4.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;javax.inject-1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;netty-3.6.2.Final.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;snappy-java-1.0.4.1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;guice-servlet-3.0.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;commons-compress-1.4.1.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;hadoop-annotations-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-client-jobclient-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-client-app-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-client-hs-plugins-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-client-common-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-client-hs-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-client-core-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-client-shuffle-2.7.2.jar:&#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;contrib&#x2F;capacity-scheduler&#x2F;*.jar</span><br><span class="line">STARTUP_MSG:   build &#x3D; Unknown -r Unknown; compiled by &#39;root&#39; on 2017-05-22T10:49Z</span><br><span class="line">STARTUP_MSG:   java &#x3D; 1.8.0_211</span><br><span class="line">************************************************************&#x2F;</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:04 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:04 INFO namenode.NameNode: createNameNode [-format]</span><br><span class="line">Formatting using clusterid: CID-8530cbf5-a4b6-454b-bfdb-2c8a016d55a7</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:05 INFO namenode.FSNamesystem: No KeyProvider found.</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:05 INFO namenode.FSNamesystem: fsLock is fair:true</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit&#x3D;1000</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check&#x3D;true</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO blockmanagement.BlockManager: The block deletion will start around 2020 Jun 25 10:00:06</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO util.GSet: Computing capacity for map BlocksMap</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO util.GSet: VM type       &#x3D; 64-bit</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO util.GSet: 2.0% max memory 966.7 MB &#x3D; 19.3 MB</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO util.GSet: capacity      &#x3D; 2^21 &#x3D; 2097152 entries</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO blockmanagement.BlockManager: dfs.block.access.token.enable&#x3D;false</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO blockmanagement.BlockManager: defaultReplication         &#x3D; 3</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO blockmanagement.BlockManager: maxReplication             &#x3D; 512</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO blockmanagement.BlockManager: minReplication             &#x3D; 1</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO blockmanagement.BlockManager: maxReplicationStreams      &#x3D; 2</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO blockmanagement.BlockManager: replicationRecheckInterval &#x3D; 3000</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO blockmanagement.BlockManager: encryptDataTransfer        &#x3D; false</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO blockmanagement.BlockManager: maxNumBlocksToLog          &#x3D; 1000</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO namenode.FSNamesystem: fsOwner             &#x3D; root (auth:SIMPLE)</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO namenode.FSNamesystem: supergroup          &#x3D; supergroup</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO namenode.FSNamesystem: isPermissionEnabled &#x3D; true</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO namenode.FSNamesystem: HA Enabled: false</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO namenode.FSNamesystem: Append Enabled: true</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO util.GSet: Computing capacity for map INodeMap</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO util.GSet: VM type       &#x3D; 64-bit</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO util.GSet: 1.0% max memory 966.7 MB &#x3D; 9.7 MB</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO util.GSet: capacity      &#x3D; 2^20 &#x3D; 1048576 entries</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO namenode.FSDirectory: ACLs enabled? false</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO namenode.FSDirectory: XAttrs enabled? true</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO namenode.FSDirectory: Maximum size of an xattr: 16384</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO namenode.NameNode: Caching file names occuring more than 10 times</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO util.GSet: Computing capacity for map cachedBlocks</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO util.GSet: VM type       &#x3D; 64-bit</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO util.GSet: 0.25% max memory 966.7 MB &#x3D; 2.4 MB</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO util.GSet: capacity      &#x3D; 2^18 &#x3D; 262144 entries</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct &#x3D; 0.9990000128746033</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes &#x3D; 0</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     &#x3D; 30000</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets &#x3D; 10</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users &#x3D; 10</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes &#x3D; 1,5,25</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO namenode.FSNamesystem: Retry cache on namenode is enabled</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO util.GSet: Computing capacity for map NameNodeRetryCache</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO util.GSet: VM type       &#x3D; 64-bit</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO util.GSet: 0.029999999329447746% max memory 966.7 MB &#x3D; 297.0 KB</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:06 INFO util.GSet: capacity      &#x3D; 2^15 &#x3D; 32768 entries</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:07 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1479747258-172.16.198.170-1593050406999</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:07 INFO common.Storage: Storage directory &#x2F;opt&#x2F;software&#x2F;bigdata&#x2F;hadoop&#x2F;data&#x2F;tmp&#x2F;dfs&#x2F;name has been successfully formatted.</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:07 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;&#x3D; 0</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:07 INFO util.ExitUtil: Exiting with status 0</span><br><span class="line">20&#x2F;06&#x2F;25 10:00:07 INFO namenode.NameNode: SHUTDOWN_MSG: </span><br><span class="line">&#x2F;************************************************************</span><br><span class="line">SHUTDOWN_MSG: Shutting down NameNode at msr-server&#x2F;192.168.74.129</span><br><span class="line">************************************************************&#x2F;</span><br></pre></td></tr></table></figure>

<p>注：如果使用云服务器配置，在编写hosts文件的时候，是以ip hostname来配置，在hadoop1主机上配置是ip必须为服务器的内网地址，其他的服务器同理。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">xxx.79 hadoop1</span><br><span class="line">xxx.58 hadoop2</span><br><span class="line">xxx.47 hadoop3</span><br></pre></td></tr></table></figure>

<h3 id="配置ssh免密码登录"><a href="#配置ssh免密码登录" class="headerlink" title="配置ssh免密码登录"></a>配置ssh免密码登录</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop1 .ssh]$ ssh-keygen -t rsa</span><br><span class="line">[root@hadoop1 .ssh]$ ssh-copy-id hadoop1</span><br><span class="line">[root@hadoop1 .ssh]$ ssh-copy-id hadoop2</span><br><span class="line">[root@hadoop1 .ssh]$ ssh-copy-id hadoop3</span><br></pre></td></tr></table></figure>

<p>集群内的三台服务器都需要这样配置一下。</p>
<h3 id="群起集群配置"><a href="#群起集群配置" class="headerlink" title="群起集群配置"></a>群起集群配置</h3><p>配置slaves：/opt/software/hadoop/etc/hadoop/slaves，通过xsync发送的其他服务器上。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop1</span><br><span class="line">hadoop2</span><br><span class="line">hadoop3</span><br></pre></td></tr></table></figure>

<h3 id="启动测试"><a href="#启动测试" class="headerlink" title="启动测试"></a>启动测试</h3><p>在第一次启动的时候必须，先格式化namenode服务器（如果在格式化的过程中失败，重新再次格式化namenode的时候，先删除logs和data文件夹，再去格式化）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop1 hadoop]$ bin&#x2F;hdfs namenode -format</span><br></pre></td></tr></table></figure>

<p>群起hdfs</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop1 hadoop]$ start-dfs.sh</span><br></pre></td></tr></table></figure>

<p>群起yarn，因为yarn的resourcemanager是配置在hadoop2上，所以在hadoop2的服务器上执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop2 hadoop]$ start-yarn.sh</span><br></pre></td></tr></table></figure>

</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">maishuren</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://www.maishuren.top/posts/hadoop/202006132303-index.html">http://www.maishuren.top/posts/hadoop/202006132303-index.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://www.maishuren.top" target="_blank">maiBlog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%85%A5%E9%97%A8/">入门</a><a class="post-meta__tags" href="/tags/hadoop/">hadoop</a></div><div class="post_share"><div class="social-share" data-image="https://code.aliyun.com/msr/blog-pic/raw/master/banner/blogbanner15.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="/img/pay-for-weichat.png" alt="微信"/><div class="post-qr-code__desc">微信</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/posts/springboot/202006141700-index.html"><img class="prev_cover" src="https://code.aliyun.com/msr/blog-pic/raw/master/banner/blogbanner17.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">SpringBoot应用：整合actuator和Admin实现SpringBoot监控</div></div></a></div><div class="next-post pull_right"><a href="/posts/gloang/202006131039-index.html"><img class="next_cover" src="https://code.aliyun.com/msr/blog-pic/raw/master/banner/blogbanner9.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">golang学习八：切片</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/posts/golang/202006182323-index.html" title="golang学习九：sort包、map、双向链表、双向循环链表"><img class="relatedPosts_cover" src="https://code.aliyun.com/msr/blog-pic/raw/master/banner/blogbanner8.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-06-18</div><div class="relatedPosts_title">golang学习九：sort包、map、双向链表、双向循环链表</div></div></a></div><div class="relatedPosts_item"><a href="/posts/golang/202006201149-index.html" title="golang学习二十一：select和GC"><img class="relatedPosts_cover" src="https://code.aliyun.com/msr/blog-pic/raw/master/banner/blogbanner7.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-06-20</div><div class="relatedPosts_title">golang学习二十一：select和GC</div></div></a></div><div class="relatedPosts_item"><a href="/posts/golang/202006201131-index.html" title="golang学习十九：日志"><img class="relatedPosts_cover" src="https://code.aliyun.com/msr/blog-pic/raw/master/banner/blogbanner24.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-06-20</div><div class="relatedPosts_title">golang学习十九：日志</div></div></a></div><div class="relatedPosts_item"><a href="/posts/goalng/202006201125-index.html" title="golang学习十八：XML操作"><img class="relatedPosts_cover" src="https://code.aliyun.com/msr/blog-pic/raw/master/banner/blogbanner18.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-06-20</div><div class="relatedPosts_title">golang学习十八：XML操作</div></div></a></div><div class="relatedPosts_item"><a href="/posts/goalng/202006201120-index.html" title="golang学习十七：反射"><img class="relatedPosts_cover" src="https://code.aliyun.com/msr/blog-pic/raw/master/banner/blogbanner7.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-06-20</div><div class="relatedPosts_title">golang学习十七：反射</div></div></a></div><div class="relatedPosts_item"><a href="/posts/goalng/202006201116-index.html" title="golang学习十六：文件操作"><img class="relatedPosts_cover" src="https://code.aliyun.com/msr/blog-pic/raw/master/banner/blogbanner4.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-06-20</div><div class="relatedPosts_title">golang学习十六：文件操作</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var requestSetting = function (from,set) {
  var from = from
  var setting = set.split(',').filter(function(item){
  return from.indexOf(item) > -1
  });
  setting = setting.length == 0 ? from :setting;
  return setting
}

var guestInfo = requestSetting(['nick','mail','link'],'nick,mail,link')
var requiredFields = requestSetting(['nick','mail','link'],'nick,mail')

window.valine = new Valine({
  el:'#vcomment',
  appId: '2i3wIjlONBKaR3lajGvjzAFG-gzGzoHsz',
  appKey: 'TeeAbRVflEynyYLIloSk30Xe',
  notify: false,
  verify: false,
  placeholder: 'Please leave your footprints',
  avatar: 'monsterid',
  meta: guestInfo,
  pageSize: '10',
  lang: 'zh-CN',
  recordIP: false,
  serverURLs: '',
  emojiCDN: '',
  emojiMaps: "",
  enableQQ: true,
  requiredFields: requiredFields
});</script></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By maishuren</div><div class="icp"><a href="http://www.beian.miit.gov.cn/" target="_blank" rel="noopener"><img class="icp-icon" src="/img/icp.png"/><span>粤ICP备20006741号</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/third-party/activate-power-mode.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
document.body.addEventListener('input', POWERMODE);
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@3/instantpage.min.js" type="module"></script><script src="/js/search/algolia.js"></script><script>var endLoading = function () {
  document.body.style.overflow = 'auto';
  document.getElementById('loading-box').classList.add("loaded")
}
window.addEventListener('load',endLoading)</script></body></html>